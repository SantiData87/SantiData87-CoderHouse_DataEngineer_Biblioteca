{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE5t45xWDihV"
      },
      "source": [
        "# Instalacion\n",
        "\n",
        "Tutorial: https://www.youtube.com/watch?v=WxWRXNna1Qw&ab_channel=coder2j\n",
        "\n",
        "Se necesita Java JDK, Python y Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DESCARGUE JAVA\n",
        "#DESCARGUE APACHE SPARK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#python -m venv .pyspark-env #ENTORNO CREADO EN CARPETA DATA\n",
        "#python -m venv .pyspark_env #ENTORNO CREADO EN CARPETA Py Notebooks\n",
        "\n",
        "#source .pyspark_env/bin/avtivate #NO PUDE HACERLO\n",
        "\n",
        "#jupyter-lab #CON ESTE CODIGO EN LA TERMINAL ABRO EL EXPLORER HACIA EL JUPYTER LAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7AUonhsDihe"
      },
      "outputs": [],
      "source": [
        "#!pip install pyspark\n",
        "#!pip install findspark\n",
        "#!pip install jupyterlab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ChatGPT: Es posible que el problema esté relacionado con la configuración de Spark. Revisa si tienes Spark instalado correctamente y si las variables de entorno necesarias están configuradas adecuadamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXbofIZLDihg"
      },
      "source": [
        "**Tengo Python 3.9 las instalaciones**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vfavaUyKDihh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['SPARK_HOME']=r'C:/Users/Sofia Medici/Desktop/DATA/Py Notebooks/DE_S6/' #ACA PUEDE ESTAR EL PROBLEMA\n",
        "os.environ['PYSPARK_DRIVER_PYTHON']='jupyter'\n",
        "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='lab'\n",
        "os.environ['PYSPARK_PYTHON']='python'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create SparkSession\u001b[39;00m\n\u001b[0;32m      5\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[1]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDE_S6_PySpark\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\java_gateway.py:100\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    964\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1435\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1435\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1444\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1451\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1452\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado"
          ]
        }
      ],
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local[1]\") \\\n",
        "        .appName(\"DE_S6_PySpark\") \\\n",
        "        .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create SparkSession \u001b[39;00m\n\u001b[0;32m      5\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[1]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEjercicios SQL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\java_gateway.py:100\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    964\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1435\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1435\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1444\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1451\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1452\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado"
          ]
        }
      ],
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession \n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local[1]\") \\\n",
        "        .appName(\"Ejercicios SQL\") \\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (3446516968.py, line 7)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    .appName(\"Ejercicios SQL\") \\\u001b[0m\n\u001b[1;37m                                 \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local[1]\") \\\n",
        "        .appName(\"Ejercicios SQL\") \\ \n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VVKIQyiFDihh"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] El sistema no puede encontrar el archivo especificado",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create SparkSession\u001b[39;00m\n\u001b[0;32m      2\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/Sofia Medici/Desktop/DATA/PySpark_Get_Started\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
            "File \u001b[1;32mc:\\Users\\Sofia Medici\\Desktop\\DATA\\Py Notebooks\\.pyspark_env\\lib\\site-packages\\pyspark\\java_gateway.py:100\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    964\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1435\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1435\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1444\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1451\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1452\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado"
          ]
        }
      ],
      "source": [
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "        .appName(\"C:/Users/Sofia Medici/Desktop/DATA/PySpark_Get_Started\") \\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w75YUoPEDihi",
        "outputId": "6fd6e157-fbc6-49d9-c85a-1097a3d6a1ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- agentid: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+-------+------------------+\n",
            "|agentid|              name|\n",
            "+-------+------------------+\n",
            "|      0|  Michele Williams|\n",
            "|      1|    Jocelyn Parker|\n",
            "|      2|Christopher Moreno|\n",
            "|      3|       Todd Morrow|\n",
            "|      4|       Randy Moore|\n",
            "|      5|        Paul Nunez|\n",
            "|      6|      Gloria Singh|\n",
            "|      7|      Angel Briggs|\n",
            "|      8|      Lisa Cordova|\n",
            "|      9|        Dana Hardy|\n",
            "|     10|           Agent X|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importar data de agents.csv\n",
        "df_agents = spark.read.option(\"header\",True) \\\n",
        "        .option(\"inferSchema\",True) \\\n",
        "        .csv(\"./agents.csv\", )\n",
        "df_agents.printSchema()\n",
        "df_agents.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxmMdtB5Dihj",
        "outputId": "fd7bc550-f606-4af2-fb8b-993bef19523a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- callid: integer (nullable = true)\n",
            " |-- agentid: integer (nullable = true)\n",
            " |-- customerid: integer (nullable = true)\n",
            " |-- pickedup: integer (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- productsold: integer (nullable = true)\n",
            "\n",
            "+------+-------+----------+--------+--------+-----------+\n",
            "|callid|agentid|customerid|pickedup|duration|productsold|\n",
            "+------+-------+----------+--------+--------+-----------+\n",
            "|     0|     10|       179|       0|       0|          0|\n",
            "|     1|      5|       691|       1|     116|          0|\n",
            "|     2|     10|        80|       1|     165|          0|\n",
            "|     3|      6|       629|       1|     128|          0|\n",
            "|     4|      8|       318|       1|     205|          0|\n",
            "|     5|      7|       319|       1|     225|          1|\n",
            "|     6|     10|       265|       1|     211|          0|\n",
            "|     7|      9|       625|       0|       0|          0|\n",
            "|     8|      5|       877|       0|       0|          0|\n",
            "|     9|      5|       191|       1|     145|          0|\n",
            "|    10|      9|       494|       0|       0|          0|\n",
            "|    11|      5|       558|       0|       0|          0|\n",
            "|    12|      3|       703|       1|     303|          0|\n",
            "|    13|      5|       684|       1|     258|          0|\n",
            "|    14|      2|       601|       1|     179|          0|\n",
            "|    15|     10|       399|       0|       0|          0|\n",
            "|    16|      8|       460|       0|       0|          0|\n",
            "|    17|     10|       858|       1|     118|          1|\n",
            "|    18|      4|       192|       0|       0|          0|\n",
            "|    19|      8|       413|       1|     180|          0|\n",
            "+------+-------+----------+--------+--------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9940"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_calls = spark.read.option(\"header\",True) \\\n",
        "        .option(\"inferSchema\",True) \\\n",
        "        .csv(\"./calls.csv\", )\n",
        "df_calls.printSchema()\n",
        "df_calls.show()\n",
        "df_calls.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KHBLCrGDihk",
        "outputId": "14d602ca-cc53-44fa-b435-d82237216f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- customerid: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- email: string (nullable = true)\n",
            " |-- company: string (nullable = true)\n",
            " |-- phonenumber: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n",
            "+----------+------------------+--------------------+--------------------+--------------------+------------+---+\n",
            "|customerid|              name|          occupation|               email|             company| phonenumber|Age|\n",
            "+----------+------------------+--------------------+--------------------+--------------------+------------+---+\n",
            "|         0|      David Melton|          Unemployed|    DMelton@zoho.com|Morris, Winters a...|409-093-0748| 16|\n",
            "|         1|  Michael Gonzalez|             Student|Gonzalez_Michael@...|  Hernandez and Sons|231-845-0673| 19|\n",
            "|         2|     Amanda Wilson|             Student|Amanda.Wilson75@v...|Mooney, West and ...|844-276-4552| 18|\n",
            "|         3|     Robert Thomas|Engineer, structural| RThomas@xfinity.com|      Johnson-Gordon|410-404-8000| 25|\n",
            "|         4|        Eddie Hall|             Surgeon|EddieHall@outlook...|          Dawson LLC|872-287-2196| 30|\n",
            "|         5|  Charles Cruz DDS|          Unemployed|CharlesDDS55@hotm...|   Mitchell and Sons|744-564-0382| 16|\n",
            "|         6|     Maria Johnson|Engineer, aeronau...|    MJohnson@aol.com|         Gibbs-Avery|448-258-9852| 22|\n",
            "|         7|    Michael Vaughn|   Librarian, public|MichaelVaughn@zoh...|            Rice LLC|275-669-5217| 30|\n",
            "|         8|Emily Anderson DDS|           Solicitor| Emily_DDS@yahoo.com|     Little and Sons|334-290-7258| 28|\n",
            "|         9|     Travis Jensen|          Unemployed|Travis.Jensen@hot...|     Edwards-Collins|106-848-8870| 13|\n",
            "|        10|        Ryan Banks|             Student|Ryan_Banks35@gmai...|Mitchell, Dean an...|465-548-1441| 21|\n",
            "|        11| Brandon Alexander|   Chemical engineer|Alexander_Brandon...|         Robbins Ltd|305-319-8515| 29|\n",
            "|        12|     Valerie Moore|          Unemployed|Moore_Valerie@ver...|       Choi and Sons|288-680-8457| 16|\n",
            "|        13|          Tina Cox|          Unemployed|Tina_Cox@protonma...|Giles, Harris and...|535-922-1854| 16|\n",
            "|        14|    Michelle Reyes|  Engineer, drilling|Michelle.Reyes@ao...|Stewart, Dawson a...|280-280-1661| 31|\n",
            "|        15|     Grace Pearson|          Unemployed|  Grace_P@yandex.com|       Taylor-Walker|973-809-0260| 14|\n",
            "|        16|       Lauren Hill|          Counsellor|Hill_Lauren73@aol...|Parsons, Nelson a...|175-283-1682| 27|\n",
            "|        17|    Kelsey Perkins|               Nurse|  Kelsey_P80@att.com|Stephenson, Mccoy...|925-021-2855| 25|\n",
            "|        18|      Zachary Howe|          Unemployed|Howe.Zachary@xfin...|Mullins, Dawson a...|556-773-8367|  0|\n",
            "|        19|  Elizabeth Harris|          Unemployed|Elizabeth_Harris3...|Grant, Bowman and...|177-551-8499| 11|\n",
            "+----------+------------------+--------------------+--------------------+--------------------+------------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importar data de customers.csv\n",
        "df_customers = spark.read.option(\"header\",True) \\\n",
        "        .option(\"inferSchema\",True) \\\n",
        "        .csv(\"./customers.csv\", )\n",
        "df_customers.printSchema()\n",
        "df_customers.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HhXhlisDihl"
      },
      "outputs": [],
      "source": [
        "# Create temporary tables\n",
        "df_agents.createOrReplaceTempView(\"agents\")       # Agentes\n",
        "df_calls.createOrReplaceTempView(\"calls\")         # Llamadas\n",
        "df_customers.createOrReplaceTempView(\"customers\") # Clientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS9hvpjxDihl"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "Extraer agentes cuyo nombre empiezen por M o terminen en O\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cbYk2v4Dihm",
        "outputId": "a25922da-9630-4f46-d6c8-a34bd4364822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|agentid|              name|\n",
            "+-------+------------------+\n",
            "|      0|  Michele Williams|\n",
            "|      2|Christopher Moreno|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SQL Select query\n",
        "df_ej_1 = spark.sql(\"\"\"\n",
        "select * from agents\n",
        "where name like 'M%' or name like '%o'\n",
        "\"\"\")\n",
        "df_ej_1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRprR4wLDihn"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Escriba una consulta que produzca una lista, en orden alfabético, de todas las distintas ocupaciones en la tabla Customer que contengan la palabra \"Engineer\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X97huysDDiho",
        "outputId": "40f32133-3857-4271-add6-501df2ba187d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|          Occupation|\n",
            "+--------------------+\n",
            "|Engineer, aeronau...|\n",
            "|Engineer, agricul...|\n",
            "|Engineer, automotive|\n",
            "|Engineer, biomedical|\n",
            "|Engineer, broadca...|\n",
            "|Engineer, buildin...|\n",
            "|Engineer, civil (...|\n",
            "|Engineer, civil (...|\n",
            "|Engineer, communi...|\n",
            "|Engineer, control...|\n",
            "|  Engineer, drilling|\n",
            "|Engineer, electrical|\n",
            "|Engineer, electro...|\n",
            "|    Engineer, energy|\n",
            "|      Engineer, land|\n",
            "|Engineer, mainten...|\n",
            "|Engineer, mainten...|\n",
            "|Engineer, manufac...|\n",
            "|Engineer, manufac...|\n",
            "| Engineer, materials|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_ej_2 = spark.sql(\"\"\"\n",
        "SELECT DISTINCT Occupation\n",
        "FROM customers\n",
        "WHERE Occupation LIKE '%Engineer%'\n",
        "ORDER BY Occupation\n",
        "\"\"\")\n",
        "df_ej_2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eskZpOo5Dihp"
      },
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Escriba una consulta que devuelva el ID del cliente, su nombre y una columna Mayor30 que contenga \"Sí\" si el cliente tiene más de 30 años y \"No\" en caso contrario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVUkFM8NDihp",
        "outputId": "d52cc21e-2a01-48c9-c0fb-5d86962246b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------------+------+\n",
            "|CustomerID|             Name|Over30|\n",
            "+----------+-----------------+------+\n",
            "|       392|   Zachary Wilson|   Yes|\n",
            "|       986|Zachary Stevenson|    No|\n",
            "|       421|     Zachary Ruiz|   Yes|\n",
            "|        18|     Zachary Howe|    No|\n",
            "|       883| Zachary Anderson|    No|\n",
            "|       952|    Yolanda White|    No|\n",
            "|       715|   Yesenia Wright|    No|\n",
            "|       699|    Willie Greene|   Yes|\n",
            "|       860| William Thompson|    No|\n",
            "|       289|    William Scott|    No|\n",
            "|       866|     William Rice|    No|\n",
            "|        58| William Mitchell|   Yes|\n",
            "|       973|  William Jackson|   Yes|\n",
            "|       126|     William Hess|   Yes|\n",
            "|       966|   William Garcia|    No|\n",
            "|       179|    William Davis|    No|\n",
            "|       139|    William Adams|   Yes|\n",
            "|       934|   Whitney Wright|    No|\n",
            "|       893|   Wendy Thornton|   Yes|\n",
            "|       885|    Wendy Freeman|    No|\n",
            "+----------+-----------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_ej_3 = spark.sql(\"\"\"\n",
        "SELECT CustomerID, Name,\n",
        "    CASE\n",
        "        WHEN Age >= 30 THEN 'Yes'\n",
        "        WHEN Age <  30 THEN 'No'\n",
        "        ELSE 'Missing Data'\n",
        "    END AS Over30\n",
        "FROM customers\n",
        "ORDER BY Name DESC\n",
        "\"\"\")\n",
        "df_ej_3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vopBKoFzDihp"
      },
      "source": [
        "# Ejercicio 4\n",
        "\n",
        "Escriba una consulta que devuelva todas las llamadas realizadas a clientes de la profesión de ingeniería y muestre si son mayores o menores de 30, así como si terminaron comprando el producto de esa llamada.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoykKYaPDihq",
        "outputId": "28d55382-3802-4fc3-b7dc-9d208419a378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+---------------+-----------+------+\n",
            "|CallID|CustomerID|           Name|ProductSold|Over30|\n",
            "+------+----------+---------------+-----------+------+\n",
            "|  3688|       699|  Willie Greene|          0|   Yes|\n",
            "|  1552|       699|  Willie Greene|          1|   Yes|\n",
            "|  1817|       699|  Willie Greene|          0|   Yes|\n",
            "|  6270|       699|  Willie Greene|          0|   Yes|\n",
            "|  4150|       699|  Willie Greene|          0|   Yes|\n",
            "|  4900|       699|  Willie Greene|          1|   Yes|\n",
            "|  5305|       699|  Willie Greene|          1|   Yes|\n",
            "|  6191|       699|  Willie Greene|          0|   Yes|\n",
            "|  9705|       699|  Willie Greene|          0|   Yes|\n",
            "|  9714|       699|  Willie Greene|          0|   Yes|\n",
            "|  9844|       699|  Willie Greene|          0|   Yes|\n",
            "|  1158|       973|William Jackson|          0|   Yes|\n",
            "|  1516|       973|William Jackson|          0|   Yes|\n",
            "|  1944|       973|William Jackson|          0|   Yes|\n",
            "|  3026|       973|William Jackson|          0|   Yes|\n",
            "|  3113|       973|William Jackson|          0|   Yes|\n",
            "|  3162|       973|William Jackson|          0|   Yes|\n",
            "|   827|       973|William Jackson|          0|   Yes|\n",
            "|  3780|       973|William Jackson|          1|   Yes|\n",
            "|  5100|       973|William Jackson|          0|   Yes|\n",
            "+------+----------+---------------+-----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_ej_4 = spark.sql(\"\"\"\n",
        "SELECT CallID, Cu.CustomerID, Name, ProductSold,\n",
        "    CASE\n",
        "        WHEN Age >= 30 THEN 'Yes'\n",
        "        WHEN Age <  30 THEN 'No'\n",
        "        ELSE 'Missing Data'\n",
        "    END AS Over30\n",
        "FROM customers Cu\n",
        "JOIN calls Ca ON Ca.CustomerID = Cu.CustomerID\n",
        "WHERE Occupation LIKE '%Engineer%'\n",
        "ORDER BY Name DESC\n",
        "\"\"\")\n",
        "df_ej_4.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQISnE0HDihq"
      },
      "source": [
        "# Ejercicio 5\n",
        "\n",
        "Escriba dos consultas: una que calcule las ventas totales y las llamadas totales realizadas a los clientes de la profesión de ingeniería y otra que calcule las mismas métricas para toda la base de clientes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-QqrKYwDihr",
        "outputId": "4ce2be4d-b9f4-4acc-99e1-da77b05f721a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+\n",
            "|TotalSales|NCalls|\n",
            "+----------+------+\n",
            "|       502|  2483|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_ej_5 = spark.sql(\"\"\"\n",
        "SELECT SUM(ProductSold) AS TotalSales, COUNT(*) AS NCalls\n",
        "FROM customers Cu\n",
        "JOIN calls Ca ON Ca.CustomerID = Cu.CustomerID\n",
        "WHERE Occupation LIKE '%Engineer%'\n",
        "\"\"\")\n",
        "df_ej_5.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb2brA6dDihs"
      },
      "source": [
        "# Ejercicio 6\n",
        "\n",
        "Escriba una consulta que devuelva, para cada agente, el nombre del agente, la cantidad de llamadas, las llamadas más largas y más cortas, la duración promedio de las llamadas y la cantidad total de productos vendidos. Nombra las columnas AgentName, NCalls, Shortest, Longest, AvgDuration y TotalSales.\n",
        "\n",
        "Luego ordena la tabla por AgentName en orden alfabético. (Asegúrese de incluir la cláusula WHERE PickedUp = 1 para calcular solo el promedio de todas las llamadas que fueron atendidas (de lo contrario, ¡todas las duraciones mínimas serán 0)!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCIeEECNDiht",
        "outputId": "7544555a-554a-4e92-d4e8-bf997ae75af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+------+--------+-------+-----------+----------+\n",
            "|         AgentName|NCalls|Shortest|Longest|AvgDuration|TotalSales|\n",
            "+------------------+------+--------+-------+-----------+----------+\n",
            "|           Agent X|   640|      22|    334|     180.98|       194|\n",
            "|      Angel Briggs|   591|      12|    362|     181.08|       157|\n",
            "|Christopher Moreno|   649|      47|    363|     177.98|       189|\n",
            "|        Dana Hardy|   554|      49|    356|      177.2|       182|\n",
            "|      Gloria Singh|   662|      36|    349|     182.18|       209|\n",
            "|    Jocelyn Parker|   621|      40|    336|     180.33|       184|\n",
            "|      Lisa Cordova|   639|      46|    344|     179.21|       201|\n",
            "|  Michele Williams|   685|      22|    306|     177.88|       198|\n",
            "|        Paul Nunez|   648|      -5|    323|     181.07|       194|\n",
            "|       Randy Moore|   600|      16|    326|      178.6|       177|\n",
            "|       Todd Morrow|   631|      -3|    339|     180.71|       204|\n",
            "+------------------+------+--------+-------+-----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_ej_6 = spark.sql(\"\"\"\n",
        "SELECT Name AS AgentName, COUNT(*) AS NCalls, MIN(Duration) AS Shortest, MAX(Duration) AS Longest, ROUND(AVG(Duration),2) AS AvgDuration, SUM(ProductSold) AS TotalSales\n",
        "FROM calls C\n",
        "    JOIN agents A ON C.AgentID = A.AgentID\n",
        "WHERE PickeDup = 1\n",
        "GROUP BY Name\n",
        "ORDER BY Name\n",
        "\"\"\")\n",
        "df_ej_6.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnv3fHW0Diht"
      },
      "source": [
        "# Ejercicio 7\n",
        "\n",
        "Dos métricas del desempeño de los agentes de ventas que le interesan a su empresa son:\n",
        "\n",
        "1. para cada agente, cuántos segundos en promedio les toma vender un producto cuando tienen éxito\n",
        "2. para cada agente, cuántos segundos en promedio permanecen en el teléfono antes de darse por vencidos cuando no tienen éxito. Escribe una consulta que calcule esto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LuBJbvwDihu",
        "outputId": "ae360da8-33f6-4c85-8170-9e5f8e885196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+------------------+------------------+\n",
            "|              name|    avgWhenNotSold|       avgWhenSold|\n",
            "+------------------+------------------+------------------+\n",
            "|           Agent X|109.81705639614856|             185.5|\n",
            "|      Angel Briggs|108.66160220994475|180.56050955414014|\n",
            "|Christopher Moreno| 112.4882108183079|182.03703703703704|\n",
            "|        Dana Hardy| 97.73082706766917|182.30769230769232|\n",
            "|      Gloria Singh|115.41143654114366|181.10047846889952|\n",
            "|    Jocelyn Parker|118.99848484848485| 181.7608695652174|\n",
            "|      Lisa Cordova|110.09470752089136|176.46766169154228|\n",
            "|  Michele Williams|111.77763496143959|176.18686868686868|\n",
            "|        Paul Nunez|113.24380165289256| 181.0257731958763|\n",
            "|       Randy Moore|107.28611898016997|177.47457627118644|\n",
            "|       Todd Morrow|109.15677966101696|180.12745098039215|\n",
            "+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_ej_7 = spark.sql(\"\"\"\n",
        "SELECT a.name,\n",
        "SUM(\n",
        "   CASE\n",
        "       WHEN productsold = 0 THEN duration\n",
        "       ELSE 0\n",
        "   END)/SUM(\n",
        "   CASE\n",
        "       WHEN productsold = 0 THEN 1\n",
        "       ELSE 0\n",
        "   END)\n",
        "AS avgWhenNotSold ,\n",
        "SUM(\n",
        "   CASE\n",
        "       WHEN productsold = 1 THEN duration\n",
        "       ELSE 0\n",
        "   END)/SUM(\n",
        "       CASE WHEN productsold = 1 THEN 1\n",
        "       ELSE 0\n",
        "   END)\n",
        "AS avgWhenSold\n",
        "FROM calls c\n",
        "JOIN agents a ON c.agentid = a.agentid\n",
        "GROUP BY a.name\n",
        "ORDER BY 1\n",
        "\"\"\")\n",
        "df_ej_7.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
